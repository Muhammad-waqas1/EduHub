{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-10-08T17:47:58.422343Z",
          "start_time": "2021-10-08T17:47:58.301246Z"
        },
        "id": "r7eyxrMVhVy8"
      },
      "outputs": [],
      "source": [
        "# Example 1: Greeting\n",
        "\n",
        "def greet(person_name):\n",
        "    \"\"\"\n",
        "    This function greets the person passed in as a parameter\n",
        "    \"\"\"\n",
        "    print(\"Hello, \" + person_name + \". Good morning!\")   # No output!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-10-08T17:47:59.718728Z",
          "start_time": "2021-10-08T17:47:59.626442Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVwSZArdhVy-",
        "outputId": "f1dfce25-c5e3-40a2-da4f-181b564954aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello, Haris. Good morning!\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(greet(\"Haris\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmkR5nQRg_AV"
      },
      "source": [
        "# **openai**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yF9-QkjnQBY"
      },
      "source": [
        "## **Installing of open.ai**\n",
        "use the following command to install the open.ai\n",
        "\n",
        "In openai, make different api's and make them public\n",
        "\n",
        "only race is who makes first\n",
        "\n",
        "GPT is known to everybody but Perplexity and Bard users are much less\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5LIb4NRg_2N",
        "outputId": "a7052ca5-7261-4a61-cf13-cc43b58783ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.8.0-py3-none-any.whl (222 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/222.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/222.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m222.3/222.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Collecting typing-extensions<5,>=4.7 (from openai)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: typing-extensions, h11, httpcore, httpx, openai\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 openai-1.8.0 typing-extensions-4.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSUfT478naYu"
      },
      "source": [
        "## **Importing the openai in the code**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXpm-sjvncA_"
      },
      "outputs": [],
      "source": [
        "import openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAd8SvEd-vn_"
      },
      "source": [
        "If you don't have API key use deeplearning.ai environment on the given link below and practise there without api key\n",
        "https://learn.deeplearning.ai/courses/ai-agents-in-langgraph/lesson/c1l2c/build-an-agent-from-scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Y9KRsJTnexe"
      },
      "source": [
        "## **Using the open.ai key in the code**\n",
        "to generate the key you can go to the link\n",
        "https://platform.openai.com/account/api-keys\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hg23QsaZnhEs"
      },
      "outputs": [],
      "source": [
        "#Use this option ONE if you have api key\n",
        "openai.api_key = 'sk-YOUR_API_KEY'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZUReXjB-jzC"
      },
      "outputs": [],
      "source": [
        "#Option TWO if no api key and working in deeplearning.ai\n",
        "client = OpenAI()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nnKSL2jz-k_b"
      },
      "outputs": [],
      "source": [
        "chat_completion = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Hello world\"}]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8-P0F6J-odY"
      },
      "outputs": [],
      "source": [
        "chat_completion.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNz69OeinkBn"
      },
      "source": [
        "## **Sentiment Analysis using open.ai api**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vupsq_FPnqfr"
      },
      "source": [
        "To read the more about the examples on chatgpt\n",
        "https://platform.openai.com/examples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6pz6CXo1nnYb"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "\n",
        "openai.api_key = 'sk-YOUR_API_KEY'\n",
        "\n",
        "#The system message tells the model who it is and how to act (a professional writer).\n",
        "#The user message tells the model what to do (write a blog).\n",
        "\n",
        "def Senitment_analysis(text):\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"\"\"You are trained to analyze and detect the sentiment of given text.\n",
        "                                        If you're unsure of an answer, you can say \"not sure\" and recommend users to review manually.\"\"\"},\n",
        "        {\"role\": \"user\", \"content\": f\"\"\"Analyze the following text and determine if the sentiment is: positive or negative.\n",
        "                                        Return answer in single word as either positive or negative: {text}\"\"\"}\n",
        "        ]\n",
        "\n",
        "\n",
        "#gpt-3 context window 4000 tokens\n",
        "#gpt-3.5 turbo context window sixteen thousand tokens\n",
        "#Standard: ~ 8,192 tokens GPT-4 with extended context (e.g. “GPT-4-32k”) approx. 32,768 tokens\n",
        "#GPT-4 Turbo / latest “Turbo” versions: up to 128,000 tokens\n",
        "#improved latency, enhanced output, more efficient as you switch from one LLM to another\n",
        "    response = openai.chat.completions.create(model=\"gpt-4\",\n",
        "                                              messages=messages,\n",
        "                                              max_tokens=1,\n",
        "                                              n=1,\n",
        "                                              temperature=0)#temperature is te creativity\n",
        "\n",
        "    response_text = response.choices[0].message.content.strip().lower()\n",
        "\n",
        "\n",
        "    return response_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvybKxXRnweT",
        "outputId": "ecd85702-76f3-4a20-b5f4-fb8ed91c8f6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I hate fast food : The Sentiment is negative\n"
          ]
        }
      ],
      "source": [
        "# calling the function\n",
        "input = 'I hate fast food'\n",
        "response = Senitment_analysis(input)\n",
        "print(input,': The Sentiment is', response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnQ5heQzntjF"
      },
      "source": [
        "## **generating the blog using the open ai api**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eohFLnQNn13_"
      },
      "outputs": [],
      "source": [
        "def generate_blog(topic):\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"\"\"You are trained to analyze a topic and generate a blog post.\n",
        "                                        The blog post must contain 1500 to 3000 words (No less than 1500 words).\"\"\"},\n",
        "        {\"role\": \"user\", \"content\": f\"\"\"Analyze the topic and generate a blog post. The topic is {topic}\n",
        "                                        The blog post should contain the following format.\n",
        "                                        1) Title (Not more than one line).\n",
        "                                        2) Introduction (Give introducion about the topic)\n",
        "                                        3) Add an image url relevent to the topic.\n",
        "                                        4) Add 2/3 subheadings and explain them.\n",
        "                                        5) Body (should describe the facts and findings)\n",
        "                                        6) Add an image url relevent to the topic.\n",
        "                                        7) Add 2/3 subheadings and explain them.\n",
        "                                        8) General FAQ regarding the topic.\n",
        "                                        9) Conclusion of the topic. \"\"\"}\n",
        "        ]\n",
        "\n",
        "\n",
        "\n",
        "    response = openai.chat.completions.create(model=\"gpt-4\",\n",
        "                                              messages=messages,\n",
        "                                              max_tokens=3000,\n",
        "                                              n=1,\n",
        "                                              temperature=0.5)\n",
        "\n",
        "    response_text = response.choices[0].message.content.strip().lower()\n",
        "\n",
        "    return response_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63i2UDfwoAmg",
        "outputId": "c3751fd7-a0bf-4dea-d4ae-cefd8d0460c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "title: machine learning: unleashing the power of artificial intelligence\n",
            "\n",
            "introduction:\n",
            "machine learning has emerged as one of the most exciting and transformative fields in the realm of artificial intelligence. with its ability to enable computers to learn and improve from experience without explicit programming, machine learning is revolutionizing various industries and transforming the way we interact with technology. in this blog post, we will delve into the world of machine learning, exploring its applications, techniques, and potential impact on society.\n",
            "\n",
            "image url: [insert relevant image url here]\n",
            "\n",
            "subheading 1: supervised learning: teaching machines to make predictions\n",
            "supervised learning is one of the most common and foundational techniques in machine learning. it involves training a model using labeled data, where the input variables (features) are paired with the correct output variables (labels). the model then learns patterns and relationships within the data to make predictions or classify new, unseen data.\n",
            "\n",
            "in supervised learning, the machine learning algorithm is provided with a dataset that includes both input and output variables. the algorithm learns from this labeled data to generalize patterns and make accurate predictions on new, unseen data. this technique is widely used in various applications, including spam detection, image recognition, and sentiment analysis.\n",
            "\n",
            "subheading 2: unsupervised learning: discovering hidden patterns\n",
            "unsupervised learning, on the other hand, deals with unlabeled data, where the algorithm must find patterns and structures within the data without any prior knowledge of the output variables. unlike supervised learning, unsupervised learning algorithms work on their own to discover hidden patterns, relationships, and structures in the data.\n",
            "\n",
            "clustering is a popular technique in unsupervised learning, where the algorithm groups similar data points together based on their inherent similarities. this can be useful in customer segmentation, anomaly detection, and recommendation systems. another technique is dimensionality reduction, which aims to reduce the number of input variables while preserving the most relevant information. this helps in visualizing high-dimensional data and improving computational efficiency.\n",
            "\n",
            "subheading 3: reinforcement learning: learning through trial and error\n",
            "reinforcement learning takes inspiration from how humans learn through trial and error. in this approach, an agent interacts with an environment and learns to maximize a reward signal by taking appropriate actions. the agent receives feedback in the form of rewards or penalties, which guides its learning process.\n",
            "\n",
            "through repeated interactions, the reinforcement learning algorithm explores different actions and learns to make decisions that lead to the maximum cumulative reward. this technique has been successfully applied in various domains, such as autonomous driving, robotics, and game playing. notably, reinforcement learning algorithms have achieved remarkable milestones, including defeating human champions in complex games like go and poker.\n",
            "\n",
            "image url: [insert relevant image url here]\n",
            "\n",
            "subheading 4: deep learning: unlocking the power of neural networks\n",
            "deep learning is a subfield of machine learning that focuses on artificial neural networks, inspired by the structure and function of the human brain. these neural networks consist of multiple layers of interconnected nodes (neurons) that process and transform data. deep learning has gained immense popularity due to its ability to handle complex tasks, such as image and speech recognition, natural language processing, and autonomous driving.\n",
            "\n",
            "deep learning models, known as deep neural networks, learn hierarchical representations of data by progressively extracting higher-level features from raw input data. this allows them to automatically learn intricate patterns and relationships, leading to state-of-the-art performance in various domains. the availability of vast amounts of data and advancements in computing power have been instrumental in the success of deep learning.\n",
            "\n",
            "subheading 5: the impact of machine learning on society\n",
            "machine learning has the potential to transform numerous aspects of our society. from healthcare to finance, transportation to entertainment, machine learning is revolutionizing industries and creating new opportunities.\n",
            "\n",
            "in healthcare, machine learning algorithms can analyze medical images, predict diseases, and assist in drug discovery. in finance, machine learning models can predict stock prices, detect fraud, and automate trading strategies. in transportation, machine learning is vital for autonomous vehicles, optimizing traffic flow, and predicting maintenance needs. in entertainment, recommendation systems powered by machine learning algorithms suggest personalized content to users.\n",
            "\n",
            "machine learning also raises ethical considerations, such as bias in algorithms, privacy concerns, and the impact on employment. it is crucial to address these challenges to ensure the responsible and ethical use of machine learning technologies.\n",
            "\n",
            "general faq:\n",
            "q1. what is the difference between artificial intelligence and machine learning?\n",
            "a1. artificial intelligence (ai) is a broader field that encompasses the development of intelligent machines capable of simulating human intelligence. machine learning, on the other hand, is a subset of ai that focuses on algorithms and models that enable computers to learn from data and improve their performance without explicit programming.\n",
            "\n",
            "q2. what are some popular machine learning algorithms?\n",
            "a2. some popular machine learning algorithms include linear regression, logistic regression, decision trees, random forests, support vector machines, k-nearest neighbors, and neural networks.\n",
            "\n",
            "q3. how do i get started with machine learning?\n",
            "a3. to get started with machine learning, it is recommended to have a solid foundation in mathematics, statistics, and programming. learning python, which has popular libraries like scikit-learn and tensorflow, is a good starting point. online courses, tutorials, and hands-on projects can also help in gaining practical experience.\n",
            "\n",
            "conclusion:\n",
            "machine learning has revolutionized the field of artificial intelligence, enabling computers to learn from data and make accurate predictions or decisions. with its various techniques, such as supervised learning, unsupervised learning, reinforcement learning, and deep learning, machine learning has found applications in numerous domains, impacting society in profound ways. as we continue to explore the potential of machine learning, it is essential to ensure its responsible and ethical use while addressing the challenges that arise. the future of machine learning holds immense promise, and its continued advancements will shape the world we live in.\n"
          ]
        }
      ],
      "source": [
        "user_input =\"Machine Learning\"\n",
        "blog = generate_blog(user_input)\n",
        "print(blog)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WGGUdm4_0zJ"
      },
      "source": [
        "**HELPFUL ASSISTANT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8KAFoMPJ59ph"
      },
      "outputs": [],
      "source": [
        "\n",
        "def ask_ai(question):\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": question}\n",
        "    ]\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=messages,\n",
        "        max_tokens=100\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "print(ask_ai(\"Explain cloud computing in one sentence\"))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gist": {
      "data": {
        "description": "01_Learn_Python4Data/04_Python_Functions/001_Python_Functions.ipynb",
        "public": true
      },
      "id": ""
    },
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
